{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67b6073",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 03:29:51.226311: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 03:29:51.338124: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-16 03:29:51.341948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-16 03:29:51.341960: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-16 03:29:51.817158: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-16 03:29:51.817252: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-16 03:29:51.817258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-05-16 03:29:54.877422: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-05-16 03:29:54.877446: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-16 03:29:54.877467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2023-05-16 03:29:54.877761: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFDistilBertForQuestionAnswering were initialized from the model checkpoint at distilbert-base-cased-distilled-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/envs/sp/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f52cce3e830>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f52cc7e1540>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f52ccb5c1c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f52ccb5ee00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f52ccb61a80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f52ccb6c700>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, LayerNorm_layer_call_fn while saving (showing 5 of 164). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./distilbert-base-cased-distilled-squad/saved_model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./distilbert-base-cased-distilled-squad/saved_model/1/assets\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForQuestionAnswering, DistilBertTokenizer \n",
    "import tensorflow as tf\n",
    "\n",
    "MODEL_NAME = 'distilbert-base-cased-distilled-squad'\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.save_pretrained('./{}_tokenizer/'.format(MODEL_NAME))\n",
    "\n",
    "try:\n",
    "    model = TFDistilBertForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
    "except:\n",
    "    model = TFDistilBertForQuestionAnswering.from_pretrained(MODEL_NAME, from_pt=True)\n",
    "    \n",
    "# Define TF Signature\n",
    "@tf.function(\n",
    "  input_signature=[\n",
    "      {\n",
    "          \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n",
    "          \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\")       \n",
    "      }\n",
    "  ]\n",
    ")\n",
    "def serving_fn(input):\n",
    "    return model(input)\n",
    "\n",
    "model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True, signatures={\"serving_default\": serving_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265a8902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 254796\r\n",
      "-rw-r--r-- 1 root root       569 May 16 03:30 config.json\r\n",
      "drwxr-xr-x 3 root root      4096 May 16 03:30 saved_model\r\n",
      "-rw-r--r-- 1 root root 260895720 May 16 03:30 tf_model.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b770b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4972\r\n",
      "drwxr-xr-x 2 root root    4096 May 16 03:30 assets\r\n",
      "-rw-r--r-- 1 root root      57 May 16 03:30 fingerprint.pb\r\n",
      "-rw-r--r-- 1 root root   79098 May 16 03:30 keras_metadata.pb\r\n",
      "-rw-r--r-- 1 root root 4996317 May 16 03:30 saved_model.pb\r\n",
      "drwxr-xr-x 2 root root    4096 May 16 03:30 variables\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}/saved_model/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e195f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 220\r\n",
      "-rw-r--r-- 1 root root    125 May 16 03:29 special_tokens_map.json\r\n",
      "-rw-r--r-- 1 root root    427 May 16 03:29 tokenizer_config.json\r\n",
      "-rw-r--r-- 1 root root 213450 May 16 03:29 vocab.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d27caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_path = '{}/saved_model/1/assets'.format(MODEL_NAME)\n",
    "\n",
    "!cp {MODEL_NAME}_tokenizer/vocab.txt {asset_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce3e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 212\r\n",
      "-rw-r--r-- 1 root root 213450 May 16 03:30 vocab.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}/saved_model/1/assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcbd089c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/root/miniconda3/envs/sp/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-aa0a5bb8-7683-41ed-853b-1c929e11a6cf;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;4.4.2 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.16.0 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.16 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.42.3 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.42.3 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.42.3 in central\n",
      "\tfound com.google.api-client#google-api-client;2.1.1 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.42.3 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.9.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.9.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.42.3 in central\n",
      "\tfound com.google.api#gax-httpjson;0.105.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.9.0 in central\n",
      "\tfound io.grpc#grpc-core;1.51.0 in central\n",
      "\tfound com.google.api#gax;2.20.1 in central\n",
      "\tfound com.google.api#gax-grpc;2.20.1 in central\n",
      "\tfound io.grpc#grpc-alts;1.51.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.51.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.51.0 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.13.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.13.0 in central\n",
      "\tfound com.google.api#api-common;2.2.2 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound io.grpc#grpc-context;1.51.0 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.6.22 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.10 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.10 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.11.0 in central\n",
      "\tfound org.threeten#threetenbp;1.6.4 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.16.0-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.16.0-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.16.0-alpha in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.14.1 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.51.0 in central\n",
      "\tfound io.grpc#grpc-auth;1.51.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.51.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.28.0 in central\n",
      "\tfound com.google.api.grpc#grpc-google-iam-v1;1.6.22 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.51.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.51.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.51.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.51.0 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.51.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      ":: resolution report :: resolve 725ms :: artifacts dl 27ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.14.1 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.2.2 from central in [default]\n",
      "\tcom.google.api#gax;2.20.1 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.20.1 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.105.1 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.1.1 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.16.0-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.16.0-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-iam-v1;1.6.22 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.16.0-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.11.0 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.6.22 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.13.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.13.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.9.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.9.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.9.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.16.0 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.16 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.42.3 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.42.3 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.42.3 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.42.3 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.42.3 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.10 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.10 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;4.4.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.51.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.28.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.4 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.10] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.10] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   73  |   0   |   0   |   3   ||   70  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-aa0a5bb8-7683-41ed-853b-1c929e11a6cf\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 70 already retrieved (0kB/18ms)\n",
      "23/05/16 03:30:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "# let's start Spark with Spark NLP\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\", \"16G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\")\\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000m\")\\\n",
    "    .config(\"spark.jsl.settings.pretrained.cache_folder\", \"sample_data/pretrained\")\\\n",
    "    .config(\"spark.jsl.settings.storage.cluster_tmp_dir\", \"sample_dataorage\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.4.1\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee4b5fbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "MODEL_NAME = 'distilbert-base-cased-distilled-squad'\n",
    "\n",
    "spanClassifier = DistilBertForQuestionAnswering.loadSavedModel(\n",
    "     '{}/saved_model/1/'.format(MODEL_NAME),\n",
    "     spark\n",
    " )\\\n",
    "  .setInputCols([\"document_question\",'document_context'])\\\n",
    "  .setOutputCol(\"answer\")\\\n",
    "  .setCaseSensitive(True)\\\n",
    "  .setMaxSentenceLength(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6774ee49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spanClassifier.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56aec720",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "282a0fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 259516\r\n",
      "-rw-r--r-- 1 root root 265735555 May 16 03:30 distilbert_classification_tensorflow\r\n",
      "drwxr-xr-x 4 root root      4096 May 16 03:30 fields\r\n",
      "drwxr-xr-x 2 root root      4096 May 16 03:30 metadata\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}_spark_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0792a92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|result |\n",
      "+-------+\n",
      "|[Clara]|\n",
      "+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "document_assembler = MultiDocumentAssembler() \\\n",
    "    .setInputCols([\"question\", \"context\"]) \\\n",
    "    .setOutputCols([\"document_question\", \"document_context\"])\n",
    "\n",
    "spanClassifier_loaded = DistilBertForQuestionAnswering.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n",
    "  .setInputCols([\"document_question\",'document_context'])\\\n",
    "  .setOutputCol(\"answer\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    spanClassifier_loaded\n",
    "])\n",
    "\n",
    "example = spark.createDataFrame([[\"What's my name?\", \"My name is Clara and I live in Berkeley.\"]]).toDF(\"question\", \"context\")\n",
    "result = pipeline.fit(example).transform(example)\n",
    "\n",
    "result.select(\"answer.result\").show(1, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "sp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
